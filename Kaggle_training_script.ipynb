{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.455537Z","iopub.status.busy":"2024-06-13T20:27:25.454994Z","iopub.status.idle":"2024-06-13T20:27:25.632999Z","shell.execute_reply":"2024-06-13T20:27:25.632009Z","shell.execute_reply.started":"2024-06-13T20:27:25.455497Z"},"trusted":true},"outputs":[],"source":["import os \n","import shutil\n","import zipfile\n","from tqdm.auto import tqdm\n","is_kaggle = os.path.exists('/kaggle')\n","\n","if is_kaggle and not os.path.exists('./images_tags_final/'):\n","    os.makedirs('images_tags_final',exist_ok=True)\n","    if os.path.exists('/kaggle/input/sdchairs/images_tags_final.zip'):\n","        with zipfile.ZipFile('/kaggle/input/sdchairs/images_tags_final/'+file, 'r') as zip_ref:\n","            zip_ref.extractall('./images_tags_final/')\n","    else:\n","        p = '/kaggle/input/sdchairs/images_tags_final' \n","        if os.path.exists('/kaggle/input/sdchairs/images_tags_final/images_tags_final'):\n","            p += '/images_tags_final/'\n","      \n","        for file in tqdm(os.listdir(p)):\n","            shutil.copy(p+file,'./images_tags_final/'+file)\n","\n","        shutil.copy('/kaggle/input/sdchairs/meta_cap_buckets.json','./meta_cap_buckets.json')\n","\n","import json \n","data = json.load(open('./meta_cap_buckets.json','rb'))\n","replace_parent_dirs = list(data.keys())[0].split('images_tags_final')[0]\n","replace_parent_dirs = replace_parent_dirs[:-1] \n","#os.path.abspath('.'), replace_parent_dirs\n","new_data = {}\n","for k, v in data.items():\n","    new_data[k.replace(replace_parent_dirs,os.path.abspath('.'))] = v\n","\n","with open('./meta_cap_buckets.json','w') as f:\n","    json.dump(new_data, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.635052Z","iopub.status.busy":"2024-06-13T20:27:25.634742Z","iopub.status.idle":"2024-06-13T20:27:25.643427Z","shell.execute_reply":"2024-06-13T20:27:25.642554Z","shell.execute_reply.started":"2024-06-13T20:27:25.635027Z"},"trusted":true},"outputs":[],"source":["import os \n","\n","image_dir = './images_tags_final' \n","\n","\n","#metadata_file = 'C:\\piyo\\piyo_md.json'\n","\n","epochs = 7\n","your_number_of_unique_images = 5234\n","resolution = 512\n","batch_size = 1\n","num_repeats = 1\n","gradient_accumulation_steps = 2\n","\n","temp_n_updates_per_epoch = (your_number_of_unique_images*num_repeats)//(gradient_accumulation_steps*batch_size)\n","max_train_steps = epochs * temp_n_updates_per_epoch\n","#max_bucket_reso = 512\n","use_mixed_precision = 'fp16'\n","lr = 3e-6\n","\n","\n","\n","flip_aug = True\n","toml = f\"\"\"[general]\n","shuffle_caption = true\n","caption_extension = '.txt'\n","keep_tokens = 1\n","\n","[[datasets]]\n","#resolution = [{resolution}, {resolution}]\n","batch_size = {batch_size}\n","enable_bucket= true\n","max_bucket_reso = 1024\n","min_bucket_reso = 128\n","bucket_reso_steps = 64\n","\n","    [[datasets.subsets]]\n","    image_dir = '{image_dir}'\n","    metadata_file = '{image_dir}'\n","    keep_tokens = 1\n","    flip_aug = true\n","    num_repeats = {num_repeats}\n","    \n","\n","\"\"\"\n","# check if image_dir exists\n","if not os.path.exists(image_dir):\n","    raise Exception(f\"Image directory {image_dir} does not exist\")\n","# make it full path\n","image_dir = os.path.abspath(image_dir)\n","\n","with open('dataset_config.toml', 'w') as f:\n","    f.write(toml)\n","\n","dataset_toml = os.path.abspath('dataset_config.toml')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.644967Z","iopub.status.busy":"2024-06-13T20:27:25.644686Z","iopub.status.idle":"2024-06-13T20:27:25.655632Z","shell.execute_reply":"2024-06-13T20:27:25.654835Z","shell.execute_reply.started":"2024-06-13T20:27:25.644936Z"},"trusted":true},"outputs":[],"source":["# Sample prompts\n","# 1 von fff852e4-140f-53d4-a9be-7f4c6558abf0.jpg\n","# 2 von fa257c34-6d93-5f57-9b2c-579d8b59890f.jpg\n","training_sample_prompts = \"\"\"\n","Preis 150, Allgemeine Angaben Breite: 66cm, Allgemeine Angaben Hoehe: 98cm, Allgemeine Angaben Tiefe: 66cm, Allgemeine Angaben Gewicht 11kg, Allgemeine Angaben Farbe Dunkelgrau, Technische Details Max. Belastbarkeit 136kg, Produktmerkmale Rueckenlehne Hoehe 49cm, Armlehnen/Armteil Armlehnenhoehe 18cm, Bezug Material Textil, Material Textil, Material Oberflaeche Textil Textilgeflecht, Kundenhinweise Pflegehinweise Keine scharfen Reinigungsmittel verwenden --w 512 --h 512 --d 1 --l 7.5 --s 28\n","\n","Preis 370, Allgemeine Angaben Breite: 56cm, Allgemeine Angaben Hoehe: 86cm, Allgemeine Angaben Tiefe: 59cm, Allgemeine Angaben Gewicht 15kg, Allgemeine Angaben Farbe Braun, Artikel besteht aus Anzahl der Stuehle 2, Technische Details Anzahl der Sitzplaetze 1, Produktmerkmale Bezug Stoffzusammensetzung 100% Polyester, Material Holzwerkstoff --w 512 --h 512 --d 1 --l 7.5 --s 28\n","\n","Preis 499, Allgemeine Angaben Breite: 62cm, Allgemeine Angaben Hoehe: 90cm, Allgemeine Angaben Tiefe: 65cm, Allgemeine Angaben Farbe Haselnussfarben, Allgemeine Angaben Farbe Cognac, Allgemeine Angaben Farbe Wildeiche, Produktvorteile Zubehoer inklusive Armlehnen, Produktvorteile Gestell, Produktvorteile Besonderheiten Lederauswahl, Produktvorteile Stoffauswahl, Produktvorteile Typenauswahl, Produktvorteile inklusive Armlehnen, Produktvorteile Gestellauswahl, Artikel besteht aus Anzahl der Rueckenkissen 1, Artikel besteht aus Rueckenkissen, Technische Details Max. Belastbarkeit 140kg, Armlehnen/Armteil Armlehnenhoehe 66cm, Material Oberflaeche geoelt, Material Lederart Kombination Echtleder/Stoff, Material Lederqualitaet Rindleder, Material Holzart Eiche, Material Holzqualitaet Echtholz, Material Echtholz massiv, Material Scheuertouren 50.000, Material Oberflaeche Leder pigmentiert, Material Lichtechtheit 5 gut, Material Abriebfestigkeit 4 gut, Material Pillingbildung 4 leicht, Material Holz, Material Textil, Material Leder, Material Oberflaeche Textil Webstoff, Material Materialzusammensetzung 100 % Polyester, Beine Farbe Eiche Bianco, Beine Anzahl der Beine 4, Beine Beinform konisch, Beine Stativgestell, Sitzflaeche Sitzbreite 42-47cm, Sitzflaeche Sitzhoehe 48cm, Sitzflaeche Sitztiefe 42cm, Innenleben Rueckenlehne Schaumstoff, Innenleben Schaumstoff, Kundenhinweise Verwendung Indoor, Kundenhinweise Lieferhinweis fuer Endkunden zerlegt, Kundenhinweise Jedes Echtholzprodukt ist ein Unikat. Woelbungen, Kundenhinweise Farbverlaeufe etc. sind warentypisch und stellen keinen Reklamationsgrund dar., Kundenhinweise Transporthinweis fuer Endkunden Kombi, Kundenhinweise Montagehinweis fuer Endkunden handwerkliche Begabung, Kundenhinweise Pflegehinweise Holzpflegemittel verwenden, Kundenhinweise Lederpflegemittel verwenden, Kundenhinweise nebelfeucht wischen, Verpackungsmasse Anzahl der Pakete 2, Verpackungsmasse Paket 1 Laenge: 65cm, Verpackungsmasse Paket 1 Breite: 65cm, Verpackungsmasse Paket 1 Hoehe: 76cm, Verpackungsmasse Paket 2 Laenge: 56cm, Verpackungsmasse Paket 2 Breite: 51cm --w 512 --h 512 --d 1 --l 7.5 --s 28\n","\"\"\"\n","# d is random seed, l classifier free guidance, s number of steps\n","\n","# display images\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","image_paths = [\n","    'images_tags_final/fff852e4-140f-53d4-a9be-7f4c6558abf0_149.90_2.jpg',\n","    'images_tags_final/fa257c34-6d93-5f57-9b2c-579d8b59890f_369.95_2.jpg',\n","    'images_tags_final/de28ad4c-0927-5ebd-b31c-2636420ac44a_499._1.jpg'\n","]\n","\n","#fig, axs = plt.subplots(1, len(image_paths), figsize=(10, 5))\n","\n","#for i, path in enumerate(image_paths):\n","#    img = Image.open(path)\n","#    axs[i].imshow(img)\n","#    axs[i].axis('off')\n","\n","#plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare kohya sd-script specific setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.656962Z","iopub.status.busy":"2024-06-13T20:27:25.656700Z","iopub.status.idle":"2024-06-13T20:27:25.717883Z","shell.execute_reply":"2024-06-13T20:27:25.716823Z","shell.execute_reply.started":"2024-06-13T20:27:25.656939Z"},"trusted":true},"outputs":[],"source":["import torch \n","import os \n","if not os.path.exists('sd-scripts'):\n","    !git clone https://github.com/kohya-ss/sd-scripts\n","    # if mps is available, install those requirements\n","    if torch.backends.mps.is_available():\n","        print('Macbook installation')\n","        !git clone --recursive https://github.com/bmaltais/kohya_ss -q\n","        os.chdir('kohya_ss')\n","        !pip install xformers bitsandbytes==0.41.1 -q\n","        !pip install tensorflow-macos tensorflow-metal tensorboard==2.14.1 -q\n","        !pip install onnxruntime==1.17.1\n","        !pip install -r requirements.txt -q\n","        os.chdir('..')\n","        # fix for xformers macos https://github.com/bmaltais/kohya_ss/issues/2071\n","        !ls /Users/amos/miniconda3/envs/sd-scripts/lib/python3.10/site-packages -q\n","        !rm -r /Users/amos/miniconda3/envs/sd-scripts/lib/python3.10/site-packages/xformers -q\n","        !rm -r /Users/amos/miniconda3/envs/sd-scripts/lib/python3.10/site-packages/xformers-0.0.26.post1.dist-info -q\n","    else: \n","\n","        os.chdir('sd-scripts')\n","\n","        ! pip install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu118 -q\n","        !pip install opencv-python>=4.9.0\n","        !pip install huggingface-hub>=0.21.2\n","        !pip install -r requirements.txt -q\n","        !pip install xformers==0.0.23.post1 --index-url https://download.pytorch.org/whl/cu118 -q\n","        \n","\n","\n","\n","        os.chdir('..')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.735139Z","iopub.status.busy":"2024-06-13T20:27:25.734352Z","iopub.status.idle":"2024-06-13T20:27:25.742817Z","shell.execute_reply":"2024-06-13T20:27:25.741768Z","shell.execute_reply.started":"2024-06-13T20:27:25.735111Z"},"trusted":true},"outputs":[],"source":["# change directory to the sd-scripts folder\n","if not is_kaggle:\n","    os.chdir('sd-scripts')\n","    # make training_metadata_tags.json file \n","    !\n","    command = f\"python finetune/merge_dd_tags_to_metadata.py --full_path {image_dir} meta_cap.json\"\n","    os.system(command)\n","\n","    !python finetune/clean_captions_and_tags.py meta_cap.json meta_cap_clean.json\n","    os.chdir('..')\n","\n","    metadata_file_path = os.path.abspath('sd-scripts/meta_cap_clean.json')"]},{"cell_type":"markdown","metadata":{},"source":["## Training\n","Only the UNet is finetuned by default, the text encoder is left as-is.\n","The base model used is https://huggingface.co/runwayml/stable-diffusion-v1-5."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.745040Z","iopub.status.busy":"2024-06-13T20:27:25.744672Z","iopub.status.idle":"2024-06-13T20:27:25.752086Z","shell.execute_reply":"2024-06-13T20:27:25.751400Z","shell.execute_reply.started":"2024-06-13T20:27:25.745016Z"},"trusted":true},"outputs":[],"source":["resume_path = None\n","if not is_kaggle and False:\n","    from huggingface_hub import hf_hub_download\n","    import os\n","    # import shutil\n","\n","    cache_dir = '.cache'\n","    os.makedirs(cache_dir, exist_ok=True)\n","    # amos: issues with symlinks (rather just download manually, put in folder and specify link manually)\n","    model = hf_hub_download(repo_id=\"runwayml/stable-diffusion-v1-5\", filename=\"v1-5-pruned.safetensors\" )\n","    model_path = os.path.abspath(model)\n","else:\n","    model_path = '/kaggle/input/sdchairs/downloaded_models/v1-5-pruned.safetensors'\n","    if os.path.exists('/kaggle/input/sdchairs/checkpoint/'):\n","        print('use checkpoint')\n","        #model_path = '/kaggle/input/sdchairs/checkpoint/'\n","        #model_path = '/kaggle/input/sdchairs/checkpoint/model.safetensors'\n","        resume_path = '/kaggle/input/sdchairs/checkpoint/'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.753308Z","iopub.status.busy":"2024-06-13T20:27:25.753048Z","iopub.status.idle":"2024-06-13T20:27:25.763275Z","shell.execute_reply":"2024-06-13T20:27:25.762393Z","shell.execute_reply.started":"2024-06-13T20:27:25.753277Z"},"trusted":true},"outputs":[],"source":["if not is_kaggle:\n","    !pip install torch==2.1.2 # fix \"torch has no attribute mps\"\n","\n","#else:\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.765103Z","iopub.status.busy":"2024-06-13T20:27:25.764523Z","iopub.status.idle":"2024-06-13T20:27:25.771373Z","shell.execute_reply":"2024-06-13T20:27:25.770430Z","shell.execute_reply.started":"2024-06-13T20:27:25.765070Z"},"trusted":true},"outputs":[],"source":["if not is_kaggle:\n","    # precompute latents (using encoder of the default model)\n","    metadata_file_path = os.path.abspath('sd-scripts/meta_cap_clean.json')\n","\n","    os.chdir('sd-scripts')\n","    command = f'python finetune/prepare_buckets_latents.py --full_path {image_dir} {metadata_file_path} meta_cap_buckets.json \"{model}\" --batch_size {batch_size} --max_resolution {max_bucket_reso},{max_bucket_reso} --mixed_precision {use_mixed_precision} --max_data_loader_n_workers=4'\n","    os.system(command)\n","    os.chdir('..')\n","    metadata_file_path = os.path.abspath('sd-scripts/meta_cap_buckets.json')\n","else:\n","    metadata_file_path = '/kaggle/working/meta_cap_buckets.json'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.774232Z","iopub.status.busy":"2024-06-13T20:27:25.773901Z","iopub.status.idle":"2024-06-13T20:27:25.802461Z","shell.execute_reply":"2024-06-13T20:27:25.801536Z","shell.execute_reply.started":"2024-06-13T20:27:25.774208Z"},"trusted":true},"outputs":[],"source":["# this code is adapted from https://github.com/Linaqruf/kohya-trainer/\n","import datetime\n","import toml\n","import os\n","import torch\n","\n","%store -r\n","\n","#model_path = '/kaggle/input/sdchairs/downloaded_models/v1-5-pruned.safetensors' #'/kaggle/working/sd-scripts/checkpoints/chair_2024-06-13_14-37-10-000001.safetensors' \n","#resume_path = None #'/kaggle/working/sd-scripts/checkpoints/chair_2024-06-13_14-37-10-000001-state'\n","\n","dataset_repeats = num_repeats #\n","output_dir = 'checkpoints'\n","# = None #'/kaggle/working/sd-scripts/checkpoints/' #None\n","#os.makedirs(output_dir, exist_ok=True)\n","\n","output_filename = f\"chair_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n","\n","enable_sample_prompt = True  # @param {type:\"boolean\"}\n","sampler = \"ddim\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n","noise_offset = 0.0  # @param {type:\"number\"}\n","# specified above max_train_steps = 10000  # @param {type:\"number\"}\n","#lr_warmup_steps = 512\n","train_batch_size = batch_size  # @param {type:\"number\"}\n","mixed_precision = 'fp16'  # @param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n","# save_state = False  # @param {type:\"boolean\"}\n","save_precision = \"fp16\"  # @param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n","#save_n_epoch_ratio = 0.2  # @param {type:\"number\"}\n","save_every_n_epochs = 7\n","save_model_as = \"safetensors\"  # @param [\"ckpt\", \"safetensors\", \"diffusers\", \"diffusers_safetensors\"] {allow-input: false}\n","max_token_length = 225  # @param {type:\"number\"}\n","clip_skip = 2  # @param {type:\"number\"}\n","gradient_checkpointing = True  # @param {type:\"boolean\"}\n","# soecufued above gradient_accumulation_steps = 1  # @param {type:\"number\"}\n","seed = -1  # @param {type:\"number\"}\n","logging_dir = \"fine_tune/logs\"\n","prior_loss_weight = 1.0\n","\n","# os.chdir(repo_dir)\n","\n","# sample_str = f\"\"\"\n","#   masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt \\\n","#   --n lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry \\\n","#   --w 512 \\\n","#   --h 768 \\\n","#   --l 7 \\\n","#   --s 28\n","# \"\"\"\n","\n","config = {\n","    \"model_arguments\": {\n","        \"v2\": False,\n","        # \"v_parameterization\": v_parameterization if v2 and v_parameterization else False,\n","        \"v_parameterization\": False,\n","        \"pretrained_model_name_or_path\": model_path,\n","        # \"vae\": vae,\n","    },\n","    \"optimizer_arguments\": {\n","        # \"min_snr_gamma\": min_snr_gamma if not min_snr_gamma == -1 else None,\n","        \"optimizer_type\": 'AdamW8bit',\n","        \"learning_rate\": lr,\n","        # \"max_grad_norm\": 1.0,\n","        # \"train_text_encoder\": train_text_encoder,\n","        # \"optimizer_args\": eval(optimizer_args) if optimizer_args else None,\n","        # \"lr_scheduler\": lr_scheduler,\n","        #\"lr_warmup_steps\": lr_warmup_steps,\n","        # \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n","        # \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n","    },\n","    \"dataset_arguments\": {\n","        \"debug_dataset\": False,\n","        \"in_json\": metadata_file_path,\n","        \"train_data_dir\": image_dir,\n","        \"dataset_repeats\": dataset_repeats,\n","        \"shuffle_caption\": True,\n","        # \"keep_tokens\": keep_tokens, # ?\n","        \"resolution\": f\"{resolution},{resolution}\",\n","        \"caption_dropout_rate\": 0,\n","        \"caption_tag_dropout_rate\": 0,\n","        \"caption_dropout_every_n_epochs\": 0,\n","        \"color_aug\": False,\n","        \"flip_aug\": flip_aug, # amos\n","        \"face_crop_aug_range\": None,\n","        \"token_warmup_min\": 1,\n","        \"token_warmup_step\": 0,\n","    },\n","    \"training_arguments\": {\n","        \"output_dir\": output_dir,\n","        \"output_name\": output_filename,\n","        \"save_precision\": save_precision,\n","        \"save_every_n_epochs\": save_every_n_epochs,\n","        #\"save_n_epoch_ratio\": save_n_epoch_ratio,\n","        \"save_last_n_epochs\": None,\n","        \"save_state\": True,\n","        \"save_last_n_epochs_state\": None, # only save last state ?\n","        \"resume\": resume_path,\n","        \"train_batch_size\": train_batch_size,\n","        \"max_token_length\": 225,\n","        \"mem_eff_attn\": False,\n","        \"xformers\": False if not torch.backends.mps.is_available() else False, #change to true again\n","        \"max_train_steps\": max_train_steps, \n","        \"max_data_loader_n_workers\": 4,\n","        \"persistent_data_loader_workers\": True,\n","        \"seed\": seed if seed > 0 else None,\n","        \"gradient_checkpointing\": gradient_checkpointing,\n","        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n","        \"mixed_precision\": mixed_precision,\n","        # \"clip_skip\": clip_skip if not v2 else None,\n","        \"logging_dir\": logging_dir,\n","        \"log_prefix\": output_filename,\n","        \"noise_offset\": noise_offset if noise_offset > 0 else None,\n","    },\n","    \"sample_prompt_arguments\": {\n","        #\"sample_every_n_steps\": 100 if enable_sample_prompt else 999999,\n","        \"sample_every_n_epochs\": 1,\n","        \"sample_sampler\": sampler,\n","    },\n","    \"saving_arguments\": {\n","        \"save_model_as\": save_model_as\n","    },\n","}\n","\n","config_path = os.path.abspath(\"config_file.toml\")\n","prompt_path = os.path.abspath(\"sample_prompt.txt\")\n","\n","for key in config:\n","    if isinstance(config[key], dict):\n","        for sub_key in config[key]:\n","            if config[key][sub_key] == \"\":\n","                config[key][sub_key] = None\n","    elif config[key] == \"\":\n","        config[key] = None\n","\n","config_str = toml.dumps(config)\n","\n","def write_file(filename, contents):\n","    with open(filename, \"w\") as f:\n","        f.write(contents)\n","\n","write_file(config_path, config_str)\n","write_file(prompt_path, training_sample_prompts)\n","\n","print(config_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.803976Z","iopub.status.busy":"2024-06-13T20:27:25.803631Z","iopub.status.idle":"2024-06-13T20:27:25.814129Z","shell.execute_reply":"2024-06-13T20:27:25.813419Z","shell.execute_reply.started":"2024-06-13T20:27:25.803944Z"},"trusted":true},"outputs":[],"source":["model_path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.815461Z","iopub.status.busy":"2024-06-13T20:27:25.815162Z","iopub.status.idle":"2024-06-13T20:27:25.821803Z","shell.execute_reply":"2024-06-13T20:27:25.820965Z","shell.execute_reply.started":"2024-06-13T20:27:25.815438Z"},"trusted":true},"outputs":[],"source":["#if os.path.abspath('') == '/kaggle/working':\n","#    os.makedirs('./download')\n","#    for file in os.listdir('./sd-scripts/checkpoints/sample/'):\n","#        shutil.copy('./sd-scripts/checkpoints/sample/'+file,'./download/'+file)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:27:25.823064Z","iopub.status.busy":"2024-06-13T20:27:25.822807Z","iopub.status.idle":"2024-06-13T20:28:38.598639Z","shell.execute_reply":"2024-06-13T20:28:38.597560Z","shell.execute_reply.started":"2024-06-13T20:27:25.823041Z"},"trusted":true},"outputs":[],"source":["import datetime \n","no_gpus = 1\n","accelerate_config = 'accelerate_config.toml'\n","accelerate_config = os.path.abspath(accelerate_config)\n","from accelerate.utils import write_basic_config\n","\n","if not os.path.exists(accelerate_config):\n","    write_basic_config(save_location=accelerate_config)\n","\n","#output_dir = 'checkpoints'\n","#os.makedirs(output_dir, exist_ok=True)\n","#output_filename = f\"chair_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n","\n","os.chdir('sd-scripts')\n","command = f'''accelerate launch --num_processes={no_gpus} --config_file={accelerate_config} --num_cpu_threads_per_process=1 fine_tune.py --sample_prompts={prompt_path} --config_file={config_path}'''\n","os.system(command)\n","os.chdir('..')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T20:28:38.600235Z","iopub.status.busy":"2024-06-13T20:28:38.599926Z","iopub.status.idle":"2024-06-13T20:28:39.556396Z","shell.execute_reply":"2024-06-13T20:28:39.555335Z","shell.execute_reply.started":"2024-06-13T20:28:38.600208Z"},"trusted":true},"outputs":[],"source":["!zip ./sample.zip /kaggle/working/sd-scripts/checkpoints/sample/*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["exit()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5200285,"sourceId":8702815,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
